{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hired-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn import tree\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "about-state",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('HW3_ML//p2_data//data_train.csv', header = None)\n",
    "test_df = pd.read_csv('HW3_ML//p2_data//data_test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accomplished-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_training(X, Y):\n",
    "    criteration = ['gini', 'entropy']\n",
    "    max_features = [12,13,14,15,16]\n",
    "    min_samples_split = [1, 2, 3, 4, 5]\n",
    "    trees = []\n",
    "    for i in range(15):\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=3, criterion=random.sample(criteration, 1)[0], \n",
    "                                max_features=random.sample(max_features,1)[0], min_samples_leaf=random.sample(min_samples_split,1)[0])\n",
    "        \n",
    "        clf.fit(X, Y)\n",
    "        trees.append(clf)\n",
    "    return trees\n",
    "    \n",
    "def voting(trees, test_sample):\n",
    "    predictions = []\n",
    "    for loop_tree in trees:\n",
    "        temp_prediction = loop_tree.predict(test_sample)\n",
    "        predictions.append(temp_prediction[0])\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "def testing(trees, test_samples, actual_values):\n",
    "    count = 0.0\n",
    "    total = 0.0\n",
    "    predicted_values = []\n",
    "    for i in range(len(test_samples)):\n",
    "        pred = voting(trees, [test_samples[i]])\n",
    "        if pred == actual_values[i]:\n",
    "            count += 1\n",
    "        total +=1\n",
    "        predicted_values.append(pred)\n",
    "    print(count/total)\n",
    "    print(confusion_matrix(actual_values, predicted_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stretch-approval",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6463693539165237\n",
      "[[312   0   1   0   0   0  21   6  23   0]\n",
      " [  0   0 200 137  14   0  13   0   0   0]\n",
      " [  0   0 333   6   5   0  15   5   0   0]\n",
      " [  0   0   2 325   1   0   0   8   0   0]\n",
      " [  0   0   2   6 356   0   0   0   0   0]\n",
      " [  0   0   0  98  68 159   0   1   9   0]\n",
      " [  5   0  14   6   7   0 297   3   4   0]\n",
      " [  0   0  30  21  29   4   0 278   2   0]\n",
      " [ 36   0   0   0   0  32  46  21 201   0]\n",
      " [  1   0   0 168 163   0   0   4   0   0]]\n"
     ]
    }
   ],
   "source": [
    "forest = random_forest_training(train_df.iloc[:, :-1].to_numpy(), train_df.iloc[:, -1].to_numpy())\n",
    "testing(forest, test_df.iloc[:, :-1].to_numpy(), test_df.iloc[:, -1].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-liberty",
   "metadata": {},
   "source": [
    "## adaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "upset-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoost_train(X, Y, time, the_class):\n",
    "    m = len(X)\n",
    "    classifiers = []\n",
    "    trees_weight = np.ones((time))/m\n",
    "    e = np.zeros((time))\n",
    "    w = np.ones((time, m))/m\n",
    "    Y = ((Y==the_class) - np.array([0.5]))*2\n",
    "#     print(Y)\n",
    "    for t in range(time):\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=1)\n",
    "        clf.fit(X=X,y=Y, sample_weight=w[t])\n",
    "        predicted = clf.predict(X)\n",
    "        classifiers.append(clf)\n",
    "        prediction_performance = (predicted == Y) + np.zeros((len(predicted)))\n",
    "        e[t] = np.sum(np.squeeze(w[t])*np.squeeze(1-prediction_performance))\n",
    "        trees_weight[t] = 1/2 * np.log((1-e[t])/e[t])\n",
    "        if t != time-1:\n",
    "            w[t+1] = 1/2*w[t]*1/(1-e[t])*prediction_performance + 1/2*w[t]*1/e[t]*(1-prediction_performance)\n",
    "    return classifiers, trees_weight\n",
    "\n",
    "def predict_adaBoost(X, Y, time, test_samples):\n",
    "    results = np.zeros((len(test_samples)))\n",
    "    for the_class in range(10):\n",
    "        classifiers, trees_weight = adaBoost_train(X, Y, time, the_class)\n",
    "        preds = []\n",
    "        for j in range(len(test_samples)):\n",
    "            test_sample = test_samples[j]\n",
    "            result = 0\n",
    "            for i in range(len(classifiers)):\n",
    "                pred = classifiers[i].predict([test_sample])\n",
    "                result += pred*trees_weight[i]\n",
    "                preds.append(pred[0])\n",
    "            result = (result[0]>0)*1 + (result[0]<=0)*-1\n",
    "            if result == 1:\n",
    "                results[j] = the_class\n",
    "\n",
    "    return results\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    mini = np.min(weights)\n",
    "    maxi = np.max(weights)\n",
    "    result = ((weights - mini)/maxi)\n",
    "    result /= (np.sum(result))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "green-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 5 trees:0.6615208690680389\n",
      "accuracy for 10 trees:0.6955403087478559\n",
      "accuracy for 20 trees:0.7721555174385363\n",
      "accuracy for 50 trees:0.8413379073756432\n"
     ]
    }
   ],
   "source": [
    "for i in (5, 10, 20, 50):\n",
    "    results = predict_adaBoost(train_df.iloc[:, :-1].to_numpy(), train_df.iloc[:, -1].to_numpy(), i, test_df.iloc[:, :-1].to_numpy())\n",
    "    print(f'accuracy for {i} trees:{np.mean((test_df.iloc[:, -1].to_numpy() == results) + np.zeros((1)))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-story",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "natural-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy for xgboost model: 0.967409948542024\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model = XGBClassifier(n_estimators = 600, max_depth = 2, n_jobs = 3, gamma = 0.001, base_score = 10)\n",
    "model.fit(train_df.iloc[:, :-1].to_numpy(), train_df.iloc[:,-1].to_numpy())\n",
    "result_xg = model.predict(test_df.iloc[:, :-1])\n",
    "print(f'accuracy for xgboost model: {np.sum(result_xg==test_df.iloc[:,-1])/len(result_xg)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-virgin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
